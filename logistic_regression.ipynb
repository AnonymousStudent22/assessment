{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules for preprocessing \n",
    "import os\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import natsort\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "### Function image_to_vec() will:\n",
    "####  - Read in the image file names in the directory and sort them in ascending order.\n",
    "####  - Add the directory path to each image name, so all images can be found.\n",
    "#### - Find the images using the paths.\n",
    "#### - Read in the images as grayscale\n",
    "#### - Convert the images into arrays\n",
    "#### - Return a list of image arrays and a list of each file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefile_list = os.listdir('dataset/sample_images/') # dataset of 200\n",
    "directory = 'dataset/sample_images/'\n",
    "\n",
    "#print(os.getcwd()) # check current directory\n",
    "#imagefile_list = os.listdir('test/image/') # test dataset of 200\n",
    "#directory = 'test/image/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to take image files in dir, convert them into vectors and save them to a list\n",
    "\n",
    "def image_to_vec(file_list, directory):    \n",
    "    vec_list = []\n",
    "    files = []\n",
    "    for filename in file_list:\n",
    "        if filename.endswith('.jpg'):\n",
    "            files.append(filename)\n",
    "    files = natsort.natsorted(files) # sort file names in ascending order\n",
    "    #print(files)\n",
    "    for file in files:\n",
    "      image_path = directory+file\n",
    "      #print(image_path)\n",
    "      image = np.array(imread(image_path, as_gray=True)) #read in as grayscale\n",
    "      vec_list.append(image)\n",
    "\n",
    "    return vec_list,files \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. Read in the binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv file\n",
    "tumors = pd.read_csv('./dataset/sample_labels_0_1.csv', sep=',')\n",
    "#print(tumors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split the file names and label data into their own lists. Run the file names and labels through the function that will find the images in the directory, and convert them into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data\n",
    "im_files = list(tumors['file_name']) # converting to list in order to access each filename\n",
    "labels = tumors['label']\n",
    "#print(labels)\n",
    "\n",
    "im_vecs,filenames = image_to_vec(im_files,directory) \n",
    "\n",
    "# plt.imshow(im_vecs[0], cmap='gray') #check that im_vecs has image vectors in correct order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Merge the image and label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 1)\n"
     ]
    }
   ],
   "source": [
    "data = list(zip(im_vecs,labels)) # join the image vectors and their respective labels\n",
    "data # output should show that each array is paired with its label\n",
    "print(data[0])\n",
    "#print('data type',type(data))\n",
    "#for i in range(len(data)):\n",
    "    #print('index:',i,'label:',labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Convert the image and label data into arrays X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data file: \n",
    "\n",
    "def list_to_array(list_of_tuples): # Convert the data from list type to array\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    count=0\n",
    "    for pair in list_of_tuples:\n",
    "        temp=pair[0]\n",
    "        temp2=pair[1]\n",
    "        X.append(temp)\n",
    "        Y.append(temp2)\n",
    "        count+=1\n",
    "        #print(count,'tuples converted to array') #comment out to see check function is running\n",
    "    X=np.asarray(X)\n",
    "    Y=np.asarray(Y)\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "X,Y=list_to_array(data)\n",
    "X=X.reshape(200,262144) # MAKE SURE THIS MATCHES COUNT OF DATA SAMPLES\n",
    "\n",
    "\n",
    "# Shuffle\n",
    "X, Y = shuffle(X,Y)\n",
    "#print('x shape',X.shape, 'y shape',Y.shape)\n",
    "\n",
    "#Split the data into training and test (validation) set, if there's no real test data \n",
    "##x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=0)\n",
    "\n",
    "#print('x_train shape',x_train.shape,'y_train shape',y_train.shape)\n",
    "#print('x_test shape',x_test.shape,'y_test shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape (200, 262144) Y_test.shape (200,)\n",
      "X.shape (200, 262144) Y.shape (200,)\n"
     ]
    }
   ],
   "source": [
    "imagefile_list_test = os.listdir('test/image/') # test dataset of 200\n",
    "directory_test = 'test/image/'\n",
    "tumors_test = pd.read_csv('test/labels_0_1.csv', sep=',') # binary class labels\n",
    "#print(tumors_test)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "im_files_test = list(tumors_test['file_name']) # converting to list in order to access each filename\n",
    "labels_test = tumors_test['label2']\n",
    "#print(labels_test)\n",
    "\n",
    "# Convert image to array\n",
    "im_vecs_test,filenames_test = image_to_vec(im_files_test,directory_test) \n",
    "\n",
    "#plt.imshow(im_vecs_test[0], cmap='gray') #check that im_vecs has image vectors in correct order\n",
    "\n",
    "# Join image vectors with labels\n",
    "data_test = list(zip(im_vecs_test,labels_test))\n",
    "\n",
    "# Convert list of arrays into array of arrays\n",
    "X_test,Y_test=list_to_array(data_test)\n",
    "X_test=X_test.reshape(200,262144) # MAKE SURE THIS MATCHES COUNT OF DATA SAMPLES\n",
    "\n",
    "print('X_test.shape',X_test.shape,'Y_test.shape',Y_test.shape)\n",
    "print('X.shape',X.shape,'Y.shape',Y.shape)\n",
    "\n",
    "\n",
    "# extracting training and validation data from training dataset \n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, train_size=0.7, random_state=0)\n",
    "\n",
    "X_test,Y_test = shuffle(X_test,Y_test)\n",
    "# extracting test data from test dataset and discarding training portion by asssigning\n",
    "# it to dummy variables that won't be used.\n",
    "x_dummy, x_test, y_dummy, y_test = train_test_split(X_test, Y_test, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape[0] 140\n"
     ]
    }
   ],
   "source": [
    "print('y_train.shape[0]',y_train.shape[0]) # count of samples\n",
    "\n",
    "\n",
    "def predict(z):\n",
    "    return 1. / (1. + np.exp(-z))  # z=feature vector xTrain times parameter vector theta  \n",
    "\n",
    "\n",
    "def param_update(xTrain, yTrain):\n",
    "    print('xTrain shape before',xTrain.shape) \n",
    "    new_col = np.ones((xTrain.shape[0], 1)) \n",
    "    xTrain = np.append(xTrain, new_col, axis=1)\n",
    "    print('xTrain shape after',xTrain.shape)\n",
    "    \n",
    "    #initialise parameters\n",
    "    theta = np.zeros(xTrain.shape[1])\n",
    "    epoch = 300\n",
    "    alpha = 0.01 \n",
    "    for i in range(epoch): \n",
    "        z = np.dot(xTrain, theta) # feature vector times parameter vector\n",
    "        h = predict(z)  \n",
    "        gradient = theta - alpha * np.dot(xTrain.T,(h-yTrain))/yTrain.shape[0]\n",
    "        theta = gradient       \n",
    "    return theta\n",
    "\n",
    "def train_predict(xTrain, yTrain, xVal,yTest):\n",
    "    #print('xVal shape before',xVal.shape) \n",
    "    theta = param_update(xTrain, yTrain)\n",
    "    new_col = np.ones((xVal.shape[0], 1)) \n",
    "    xVal = np.append(xVal, new_col, axis=1)\n",
    "    #print('xVal shape after',xVal.shape)\n",
    "    z = np.dot(xVal,theta)\n",
    "    h = predict(z)\n",
    "    y_pred = h >= 0.5 # true or false assignment \n",
    "    score = accuracy_score(yTest,y_pred)\n",
    "    return y_pred, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain shape before (140, 262144)\n",
      "xTrain shape after (140, 262145)\n",
      "Accuracy score 0.8166666666666667\n",
      "y_pred [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.83      0.98      0.90        50\n",
      "\n",
      "    accuracy                           0.82        60\n",
      "   macro avg       0.42      0.49      0.45        60\n",
      "weighted avg       0.69      0.82      0.75        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "y_pred,score = train_predict(x_train, y_train, x_val,y_test) \n",
    "print('Accuracy score',score)\n",
    "print('y_pred', y_pred)\n",
    "print(classification_report(y_test,y_pred)) # main classification metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
